{
 "metadata": {
  "name": "",
  "signature": "sha256:0f9223d2ddd3e37046d43bb1578139df3c7fa29d3b2f15da299cf9a0a8978d11"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from corpus_build import Corpus, hit_num, raw_file_list\n",
      "import pandas as pd\n",
      "\n",
      "corpus = Corpus(raw_file_list)\n",
      "corpus_df = corpus.compl_df_build(False)\n",
      "corpus_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>hit_num</th>\n",
        "      <th>parent_count</th>\n",
        "      <th>double_colon</th>\n",
        "      <th>let_exists</th>\n",
        "      <th>less_minus</th>\n",
        "      <th>paren_star</th>\n",
        "      <th>def_exists</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0.071901</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.002066</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.001240</td>\n",
        "      <td> 0.000413</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0.071704</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.002699</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000771</td>\n",
        "      <td> 0.000386</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0.063995</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.002695</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000337</td>\n",
        "      <td> 0.000337</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 2</td>\n",
        "      <td> 0.024707</td>\n",
        "      <td> 0.002471</td>\n",
        "      <td> 0.002471</td>\n",
        "      <td> 0.000618</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 2</td>\n",
        "      <td> 0.024352</td>\n",
        "      <td> 0.002118</td>\n",
        "      <td> 0.002647</td>\n",
        "      <td> 0.000529</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "  hit_num  parent_count  double_colon  let_exists  less_minus  paren_star  \\\n",
        "0       1      0.071901      0.000000    0.002066    0.000000    0.001240   \n",
        "1       1      0.071704      0.000000    0.002699    0.000000    0.000771   \n",
        "2       1      0.063995      0.000000    0.002695    0.000000    0.000337   \n",
        "3       2      0.024707      0.002471    0.002471    0.000618    0.000000   \n",
        "4       2      0.024352      0.002118    0.002647    0.000529    0.000000   \n",
        "\n",
        "   def_exists  \n",
        "0    0.000413  \n",
        "1    0.000386  \n",
        "2    0.000337  \n",
        "3    0.000000  \n",
        "4    0.000000  "
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "import os\n",
      "test_file_list = [filename for filename in\n",
      "                 glob.iglob(os.path.join('test/', '*'))]\n",
      "test_info = Corpus(test_file_list)\n",
      "test_info_df = test_info.compl_df_build(True)\n",
      "test_info_df['answers'] = pd.read_csv('test_fixed.csv', dtype='object')\n",
      "test_info_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>parent_count</th>\n",
        "      <th>double_colon</th>\n",
        "      <th>let_exists</th>\n",
        "      <th>less_minus</th>\n",
        "      <th>paren_star</th>\n",
        "      <th>def_exists</th>\n",
        "      <th>answers</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0.045734</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.001759</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0.063037</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.042795</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000058</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.000058</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0.047059</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.015708</td>\n",
        "      <td> 0.000561</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.000281</td>\n",
        "      <td> 0.002805</td>\n",
        "      <td> 9</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "   parent_count  double_colon  let_exists  less_minus  paren_star  def_exists  \\\n",
        "0      0.045734      0.000000    0.001759           0    0.000000    0.000000   \n",
        "1      0.063037      0.000000    0.000000           0    0.000000    0.000000   \n",
        "2      0.042795      0.000000    0.000058           0    0.000058    0.000000   \n",
        "3      0.047059      0.000000    0.000000           0    0.000000    0.000000   \n",
        "4      0.015708      0.000561    0.000000           0    0.000281    0.002805   \n",
        "\n",
        "  answers  \n",
        "0       1  \n",
        "1       4  \n",
        "2       4  \n",
        "3       4  \n",
        "4       9  "
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Choosing the Best Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "import numpy as np\n",
      "import seaborn as sbn\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "corp_train = corpus_df.values[0::,1::]\n",
      "corp_answer = corpus_df.values[0::,0]\n",
      "test_train = test_info_df.values[0::,:-1:]\n",
      "test_answer = test_info_df.values[0::1,-1]\n",
      "\n",
      "model_list = [KNeighborsClassifier(), RandomForestClassifier(), DecisionTreeClassifier()]\n",
      "# BernoulliNB(), MultinomialNB(), AdaBoostClassifier(), GaussianNB(), \n",
      "\n",
      "def run_test_model(classifier, x_train, y_train, x_test, y_test):\n",
      "\n",
      "    classifier.fit(x_train, y_train)\n",
      "    predicted = classifier.predict(x_test)\n",
      "    return metrics.f1_score(y_test, predicted)\n",
      "\n",
      "def run_rank_multiple_models(list_of_models):\n",
      "    return [(model, run_test_model(model, corp_train, corp_answer, test_train, test_answer)) \n",
      "            for model \n",
      "            in list_of_models]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 106,
       "text": [
        "array([[0.04573438874230431, 0.0, 0.001759014951627089, 0.0, 0.0, 0.0],\n",
        "       [0.06303724928366762, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.0427946089160235, 0.0, 5.7597051030987213e-05, 0.0,\n",
        "        5.7597051030987213e-05, 0.0],\n",
        "       [0.047058823529411764, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.01570827489481066, 0.0005610098176718093, 0.0, 0.0,\n",
        "        0.00028050490883590464, 0.002805049088359046],\n",
        "       [0.0, 0.0, 0.0, 0.0, 0.0, 0.002036659877800407],\n",
        "       [0.00816326530612245, 0.0, 0.0, 0.0, 0.0, 0.00816326530612245],\n",
        "       [0.013328977458346946, 0.000914733747141457, 6.533812479581836e-05,\n",
        "        0.0004573668735707285, 0.0, 0.00013067624959163673],\n",
        "       [0.05806451612903226, 0.0064516129032258064, 0.0,\n",
        "        0.0064516129032258064, 0.0, 0.0],\n",
        "       [0.0137524557956778, 0.003929273084479371, 0.0004911591355599214,\n",
        "        0.0029469548133595285, 0.0, 0.0],\n",
        "       [0.12435233160621761, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.08866995073891626, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.11084624553039332, 0.0, 0.0008939213349225268, 0.0, 0.0, 0.0],\n",
        "       [0.006644518272425249, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.0065717415115005475, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.027181688125894134, 0.001072961373390558, 0.0, 0.0,\n",
        "        0.000715307582260372, 0.00178826895565093],\n",
        "       [0.014606155451225874, 0.0, 0.0, 0.0, 0.0, 0.004173187271778821],\n",
        "       [0.019253910950661854, 0.00030084235860409147, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.058997050147492625, 0.0, 0.0, 0.0, 0.0029498525073746312, 0.0],\n",
        "       [0.0979020979020979, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.05322415557830092, 0.0015353121801432957, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.026448029621793177, 0.0001322401481089659, 0.004892885480031738,\n",
        "        0.0, 0.005554086220576567, 0.0],\n",
        "       [0.017391304347826087, 0.0, 0.0052173913043478265, 0.0, 0.0, 0.0],\n",
        "       [0.02680067001675042, 0.0, 0.0016750418760469012, 0.0, 0.0,\n",
        "        0.0016750418760469012],\n",
        "       [0.03986710963455149, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "       [0.028050490883590462, 0.0, 0.0, 0.0, 0.0, 0.001402524544179523],\n",
        "       [0.03680981595092025, 0.0, 0.0, 0.0, 0.0, 0.012269938650306749],\n",
        "       [0.029607698001480384, 0.0, 0.0, 0.0, 0.0, 0.0030594621268196396],\n",
        "       [0.05389221556886228, 0.0, 0.0, 0.0, 0.0, 0.0]], dtype=object)"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_test_model(DecisionTreeClassifier(), corp_train, corp_answer, test_train, test_answer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/zackjcooper/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/metrics/metrics.py:1773: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
        "  'recall', 'true', average, warn_for)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 107,
       "text": [
        "0.4173737373737374"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_results = run_rank_multiple_models(model_list)\n",
      "model_results.sort(key=lambda x: x[1])\n",
      "x_labels = [group[0] for group in model_results]\n",
      "x_values = [group[1] for group in model_results]  \n",
      "width = .75\n",
      "height = np.arange(len(model_results))\n",
      "mean = np.array(x_values).mean()\n",
      "\n",
      "plt.yticks(height+width/2., x_labels)\n",
      "plt.barh(height, x_values, width, color = sbn.color_palette())\n",
      "plt.axvline(mean, c='r')\n",
      "plt.rc('figure', figsize=(10, 5))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Found array with dim 30. Expected 1",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-62-03797cfd7aba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_rank_multiple_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-61-c19c6a31408c>\u001b[0m in \u001b[0;36mrun_rank_multiple_models\u001b[0;34m(list_of_models)\u001b[0m\n\u001b[1;32m     29\u001b[0m     return [(model, run_test_model(model, corp_train, corp_answer, test_train, test_answer)) \n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             in list_of_models]\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mtest_answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-61-c19c6a31408c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_rank_multiple_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     return [(model, run_test_model(model, corp_train, corp_answer, test_train, test_answer)) \n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             in list_of_models]\n\u001b[1;32m     32\u001b[0m \u001b[0mtest_answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-61-c19c6a31408c>\u001b[0m in \u001b[0;36mrun_test_model\u001b[0;34m(classifier, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_rank_multiple_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zackjcooper/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/metrics/metrics.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1396\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m   1397\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1398\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zackjcooper/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/metrics/metrics.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1493\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1496\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zackjcooper/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/metrics/metrics.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_clf_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0mlabel_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m  \u001b[0;31m# save this for later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zackjcooper/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/metrics/metrics.py\u001b[0m in \u001b[0;36m_check_clf_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_lists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/zackjcooper/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_arrays\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             raise ValueError(\"Found array with dim %d. Expected %d\"\n\u001b[0;32m--> 254\u001b[0;31m                              % (size, n_samples))\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_lists\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Found array with dim 30. Expected 1"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Pass in code file for response"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reverse_dict_match(a_dictionary, a_list):\n",
      "    \"\"\"Pass this function a dictionary and a list. it will reverse the order of the dict\n",
      "    and match the first values of the list with the dict.\"\"\"\n",
      "    reversed_dict = dict((v,k) for k,v in a_dictionary.items())\n",
      "    return [(reversed_dict.get(x),y) for x,y in a_list]\n",
      "\n",
      "def check_code_snippet(a_file, corp_train, corp_answer):\n",
      "    \n",
      "    # Ingest and featurizes file\n",
      "    request = Corpus([a_file])\n",
      "    request_df = request.compl_df_build()\n",
      "\n",
      "    # Run model\n",
      "    model_created = GaussianNB()\n",
      "    model_created.fit(corp_train, corp_answer)\n",
      "    predicted = model_created.predict(request_df.values)\n",
      "    predict_prob = model_created.predict_proba(request_df.values)\n",
      "    \n",
      "    #Pretty response\n",
      "    answer_list = list(zip(model_created.classes_, predict_prob[0]))\n",
      "    answer_list.sort(key=lambda x: x[1], reverse=True)\n",
      "    return reverse_dict_match(hit_num, answer_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "check_code_snippet('test/1', corp_train, corp_answer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}