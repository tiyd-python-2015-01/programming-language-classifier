{
 "metadata": {
  "name": "",
  "signature": "sha256:bb2286b7350a238ba5ac194e90f30571f08fb3a5d205269816ac9c27790329bc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from data_load import*\n",
      "from features import*\n",
      "from classifier import*\n",
      "from random_guesser import*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import pandas as pd\n",
      "import re\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The lists below are the basis for my features.  For the word_list and symbol_list, the program creates a feature based on the number of occurences of the word or symbol divided by the number of characters in the code snippet.  For the endings list, if the code snippet ends with one of those strings, the feature receives a value of 10.  If it doesn't have one of the listed endings, the feature is valued at 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_list = ['let', 'end', 'defn', 'function', 'fun', 'return', 'def', 'return', 'check', 'make', '->', '.format',\n",
      "             'define', '::', 'done', 'type', 'rescue', 'print', 'elif', 'clone', 'display', '$format', 'echo', 'str',\n",
      "             'join', '&&', 'val', 'Nil', 'object', '<-', '--', 'lambda', 'var', '//', 'tmpl', 'public function',\n",
      "             'stdlib', '=>', 'final', 'case', 'impl']\n",
      "symbol_list = ['$', '^', ',', ';', '&', '|', '!', '*', '@', '#']\n",
      "endings = ['end', ')', '}']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The following function creates the data frame of features based on the corpus of code snippets pulled from  the Computer Language Benchmarks game."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def data_frame_generator():\n",
      "    codelist = code_sucker()\n",
      "    typelist = type_getter()\n",
      "    df = pd.DataFrame(typelist, index=range(386))\n",
      "    df.columns = [\"Language\"]\n",
      "    df[\"Code\"] = codelist\n",
      "    df['Language'] = df.Language.apply(lambda x:x.lower())\n",
      "    for string in word_list:\n",
      "        def sub_function(code):\n",
      "            x = string_ratio(string, code)\n",
      "            return x\n",
      "        df[string] = df.Code.apply(sub_function)\n",
      "    for char in symbol_list:\n",
      "        def sub_function2(code):\n",
      "            y = character_ratio(code, char)\n",
      "            return y\n",
      "        df[char] = df.Code.apply(sub_function2)\n",
      "    for ending in endings:\n",
      "        def sub_function3(code):\n",
      "            z = string_end(ending, code)\n",
      "            return z\n",
      "        df['_' + ending] = df.Code.apply(sub_function3)\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = data_frame_generator()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The following function creates the data frame of features based on the code snippets provided for testing the classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tdata_frame_generator():\n",
      "    test_codelist = tcode_sucker()\n",
      "    df = pd.read_csv(\"test.csv\")\n",
      "    df[\"Code\"] = test_codelist\n",
      "    for string in word_list:\n",
      "        def sub_function(code):\n",
      "            x = string_ratio(string, code)\n",
      "            return x\n",
      "        df[string] = df.Code.apply(sub_function)\n",
      "    for char in symbol_list:\n",
      "        def sub_function2(code):\n",
      "            y = character_ratio(code, char)\n",
      "            return y\n",
      "        df[char] = df.Code.apply(sub_function2)\n",
      "    for ending in endings:\n",
      "        def sub_function3(code):\n",
      "            z = string_end(ending, code)\n",
      "            return z\n",
      "        df['_' + ending] = df.Code.apply(sub_function3)\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_df = tdata_frame_generator()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train, x_test, y_train, y_test = create_xy(df, test_df, word_list[0], 'Language')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "I used a Decision Tree Classifier and a Gaussian Naive Bayes Classifier.  The Gaussian NB classifier scored higher, and thus I used that in my guess_lang.py program to be run from the console.  I also made a random guesser.  This is included as a morale booster for whenever I feel like my classifiers are not sufficiently effective."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.tree import DecisionTreeClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree = DecisionTreeClassifier()\n",
      "run_classifier(tree, x_train, x_test, y_train, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "    clojure       1.00      0.75      0.86         4\n",
        "    haskell       0.50      0.67      0.57         3\n",
        "       java       1.00      0.50      0.67         2\n",
        " javascript       1.00      0.50      0.67         4\n",
        "      ocaml       1.00      1.00      1.00         2\n",
        "       perl       0.00      0.00      0.00         0\n",
        "        php       1.00      0.33      0.50         3\n",
        "     python       0.40      0.50      0.44         4\n",
        "       ruby       0.50      0.67      0.57         3\n",
        "      scala       0.40      1.00      0.57         2\n",
        "     scheme       0.00      0.00      0.00         3\n",
        "\n",
        "avg / total       0.68      0.57      0.58        30\n",
        "\n",
        "[[3 0 0 0 0 0 0 0 1 0 0]\n",
        " [0 2 0 0 0 0 0 1 0 0 0]\n",
        " [0 1 1 0 0 0 0 0 0 0 0]\n",
        " [0 0 0 2 0 0 0 1 0 1 0]\n",
        " [0 0 0 0 2 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 1 1 0 0 1 0]\n",
        " [0 0 0 0 0 1 0 2 1 0 0]\n",
        " [0 0 0 0 0 1 0 0 2 0 0]\n",
        " [0 0 0 0 0 0 0 0 0 2 0]\n",
        " [0 1 0 0 0 0 0 1 0 1 0]]\n",
        "0.575925925926\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gauss = GaussianNB()\n",
      "run_classifier(gauss, x_train, x_test, y_train, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "    clojure       1.00      1.00      1.00         4\n",
        "    haskell       1.00      0.67      0.80         3\n",
        "       java       0.67      1.00      0.80         2\n",
        " javascript       1.00      0.25      0.40         4\n",
        "      ocaml       1.00      1.00      1.00         2\n",
        "       perl       0.00      0.00      0.00         0\n",
        "        php       0.38      1.00      0.55         3\n",
        "     python       1.00      1.00      1.00         4\n",
        "       ruby       1.00      0.33      0.50         3\n",
        "      scala       0.00      0.00      0.00         2\n",
        "     scheme       1.00      1.00      1.00         3\n",
        "\n",
        "avg / total       0.85      0.73      0.72        30\n",
        "\n",
        "[[4 0 0 0 0 0 0 0 0 0 0]\n",
        " [0 2 0 0 0 0 0 0 0 1 0]\n",
        " [0 0 2 0 0 0 0 0 0 0 0]\n",
        " [0 0 0 1 0 0 3 0 0 0 0]\n",
        " [0 0 0 0 2 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 0 3 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 4 0 0 0]\n",
        " [0 0 0 0 0 1 1 0 1 0 0]\n",
        " [0 0 1 0 0 0 1 0 0 0 0]\n",
        " [0 0 0 0 0 0 0 0 0 0 3]]\n",
        "0.724545454545\n"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_guesser(y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 166,
       "text": [
        "0.06666666666666667"
       ]
      }
     ],
     "prompt_number": 166
    }
   ],
   "metadata": {}
  }
 ]
}